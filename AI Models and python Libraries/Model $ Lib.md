# 🤖 AI Libraries & Tools Used — Storymodelers' Rosetta Stone

This document outlines all AI, machine learning, and related technologies integrated or planned for the Rosetta Stone system.

---

## 🗂️ Current AI & Speech Tools

| Library/Tool           | Purpose                                |
|------------------------|----------------------------------------|
| **AssemblyAI API**     | Cloud-based speech-to-text transcription and diarization |
| **SpeechRecognition (Planned)** | Local speech input handling as fallback option |
| **PyAudio**            | Real-time audio capture from microphones |
| **Google Cloud Storage Client** | Upload transcripts and data for remote analysis |

---

## 🧠 AI & Machine Learning Technologies (Planned/Future)

| Library/Framework      | Intended Use Case                      |
|------------------------|----------------------------------------|
| **PyTorch**            | Deep learning models for emotion detection and speech analysis |
| **TensorFlow**         | Alternative for AI pipelines (if needed) |
| **Scikit-learn**       | Classical models for emotion classification or speech metrics |
| **OpenAI/LLM Integration** | Future conversational AI or meeting moderation assistance |

---

## 🎯 AI Features Roadmap

✅ Speech Transcription via AssemblyAI  
🟡 Speaker Diarization In Progress  
🟡 Emotional Arousal Detection Pipeline Planned  
🟡 Real-Time Interaction Modeling Planned  
🟡 On-Device AI for Meeting Moderation (Long-term)  

---

## 📌 Notes

- All API keys are managed via environment variables (`.env` file)
- Current AI processing is cloud-dependent; future upgrades aim for local AI capabilities
- Data pipelines ensure environmental, speech, and future physiological data contribute to comprehensive interaction modeling

---
